---
title: "Psych 1490, Assignment 2"
author: "YOUR NAME HERE!"
date: "DATE OF SUBMISSION HERE!"
output:
  html_document:
    toc: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Before you start

## How to use R Markdown documents

This file is an R Markdown file. This is a special file that lets you write R code and run it, while also writing descriptive text (like this) about the code and analyses you have in between.

Every time you see a special colored block, like the one below, **that's where you can write and run R code.** This is called an **R code chunk.** You can type normal R code in the box, with _one command per line,_ and then run all the code in the box by pressing the green triangle (kind of looks like a play button) in the top right-hand corner of the chunk.

Try playing the code below to see what happens!

```{r}
my_variable <- 2 + 2
```

You should see in your Environment pane (top right-hand of RStudio window) now that you have a variable called `my_variable`, just as if you had typed that code into the console (bottom left-hand of RStudio window, where you did Assignment 1 in Swirl) and pressed Enter to run it there.

You can also use chunks to print out outputs in your document. These outputs will be included when you export the document later, so your TA will be able to see the results of all your R code.

For example, run the following code below using the green play button and see what happens:

```{r}
my_variable
```

Now, the value assigned to `my_variable` appears in the document. Handy! You'll be using this later to show the output of correlations and t-tests, as well as graphs you'll be making.

For every question in this assignment, every time you see an _empty_ code chunk, you will be expected to _type correct code into the chunk and run it._ We've already created code chunks for every question, so you can fill in the appropriate code in each section.

Every empty chunk you should fill in is marked with a **comment** that says "Code goes here". A comment is a special small note you can leave next to R code inside of a code chunk. You have to tell R that it's a comment, and not real code, by typing the pound/hashtag-sign # _before_ anything in your comment.

```{r}
# This will not run.
# If you press the green play button on this chunk, nothing should come out!
```

Any text after a # is not "seen" as code by R until the next line break. RStudio shows this kind of "comment text" in green (or another color, depending on your color scheme).

You can comment whole lines, if you want to type complete sentences in your notes. You can also add comments at the end of a line, if you want a comment to apply to a specific line of code.

```{r}
# The code BEFORE the # runs, and the text AFTER the # doesn't run.
2 + 2 # This should still output 4 because 2 + 2 is before the comment sign
```

We recommend only typing small "notes to self" in the comments inside code chunks. You can type anything longer than a couple sentences in the "normal text" part of your document, so that it will look like normal text when you export your document later.

## Packages

While R can do a lot of amazing stuff on its own, some special types of analysis or graphing can be more easily (or stylishly) done using one of a (huge) number of "packages" that people have created specially for R. Think of R as your phone, and the packages as apps that each allow the phone to do something extra.

To use a package, you have to install it (once), and then load it (every time you re-open RStudio).

In this assignment, we'll need the assistance of two packages in particular:

* `ggplot2` is the package we'll use to make clean, attractive graphs
* `knitr` is the package we'll use to export this homework assignment to a format you can upload to Canvas

First, you can use the code below to install these two packages if you haven't already.

```{r, eval = FALSE}
# Only run this code if you HAVEN'T already installed these packages!
install.packages(c("tidyverse",
                   "knitr"))
```

Next, use the following code to _load,_ or "turn on", these packages for the current RStudio window so you can actually access the functions inside. You need to do this every time you open a new RStudio window!

```{r}
# We only need to "turn on" tidyverse
# knitr actually works behind the scenes already!
library(tidyverse)
```

Now, we're ready to get started.

TODO: INCORPORATE THIS that I removed from assignment 1:

- Class: text
  Output: >
    For the last part of this assignment, we'll create new columns in our dataframe
    for values calculated from existing columns. For example, you can use this to create
    columns that contain row-wise means of other columns.
  
- Class: text
  Output: >
    In our dataframe, we will calculate each participant's score on the "Regret Scale"
    (Schwartz et al., 2002) by averaging the scores on each of 5 different questions:
    regret1, regret2, regret3, regret4, and regret5.
  
- Class: text
  Output: 'We can use the function rowMeans() to calculate the mean value for every row of a dataframe. Then, we''ll assign the output of rowMeans() to a new column in IntroSurvey so we can keep everyone''s Regret Scale scores with all of their other data.'
  
- Class: cmd_question
  Output: >
    Run the following command to calculate the mean Regret Scale score from the 5 questions:
    IntroSurvey$regret_total <- rowMeans(cbind(IntroSurvey$regret1, IntroSurvey$regret2,
    IntroSurvey$regret3, IntroSurvey$regret4, IntroSurvey$regret5))
  CorrectAnswer: IntroSurvey$regret_total <- rowMeans(cbind(IntroSurvey$regret1, IntroSurvey$regret2, IntroSurvey$regret3, IntroSurvey$regret4, IntroSurvey$regret5))
  AnswerTests: omnitest(correctExpr = 'IntroSurvey$regret_total <- rowMeans(cbind(IntroSurvey$regret1, IntroSurvey$regret2, IntroSurvey$regret3, IntroSurvey$regret4, IntroSurvey$regret5))')
  Hint: >
    Type out the following command and paste it into the console:
    IntroSurvey$regret_total <- rowMeans(cbind(IntroSurvey$regret1, IntroSurvey$regret2,
    IntroSurvey$regret3, IntroSurvey$regret4, IntroSurvey$regret5))
  
- Class: cmd_question
  Output: >
    Now re-run names() on the IntroSurvey dataframe to check that the new variable is there.
    regret_total should show up in the names.
  CorrectAnswer: names(IntroSurvey)
  AnswerTests: omnitest(correctExpr = 'names(IntroSurvey)'); 'regret_total' %in% names(IntroSurvey)
  Hint: >
    Type out the following command and paste it into the console: names(IntroSurvey)
  
- Class: exact_question
  Output: What is the mean regret score for the class?
  CorrectAnswer: mean(IntroSurvey$regret_total)
  AnswerTests: val_rounded_equals(4.6, digits = 1)
  Hint: Call mean() on the new regret_total column.
  
- Class: exact_question
  Output: What is the mean regret score for students in Columbia College?
  CorrectAnswer: mean(IntroSurvey$regret_total[IntroSurvey$CC == "CC"])
  AnswerTests: val_rounded_equals(4.8, digits = 1)
  Hint: >
    Call mean() on the appropriate subset of the regret_total column using hard-bracket
    indexing with a logical statement inside.



In this document, we will be modeling a specific order of R tasks:

1. Load your raw data
2. Prepare your data for analysis
3. Generate descriptive statistics
4. Generate inferential statistics
5. Generate graphs

This is important because R documents execute their code **in order** from **beginning to end,** or **from top to bottom.** All the code at the end of the document _assumes_ that code at the beginning of the document has _already been run._ For example, if you want to run a t-test on a particular mean questionnaire score that you must calculate from your raw data, the code to calculate that mean score needs to come _before_ the code that runs the t-test.

# Loading raw data into R

The _first_ thing you do in any data analysis document is to load your fresh raw data into R so you can later work with and calculate statistics on your data.

## 1.

Check your working directory using `getwd()`. If you opened RStudio via the R project file in the same directory that contains your datafile (`classdata_2019.csv`) and your R scripts, you should be in that folder now.

```{r}
# Code goes here

```

## 2.

Read in your data file using `read_csv("classdata_2019.csv")`, and assign it to the dataframe name `IntroSurvey` using the `<-` left-arrow operator.

```{r}
# Code goes here

```

## 3.

Use the following exploration functions to check that the dataframe `IntroSurvey` read in correctly:

`head()`
 
```{r}
# Code goes here

```
 
`summary()`
 
```{r}
# Code goes here

```
 
`str()`
 
```{r}
# Code goes here

```

# Cleaning and manipulating your data

Before we calculate any statistics on our data, we may need to clean the raw data, or calculate additional values of interest in our data. It is important to do this before calculating any statistics, so that any values you may need for your statistics are already present in your data by the time you run your "analysis" code.

## 4. Generating new columns of data

### a. Continuous variables: calculating overall scores for Regret and Maximization scales

First, we will show you how to create new columns in your data.

The code below will calculate two new columns based on existing raw data in `IntroSurvey`:

* `regret_total`, for overall Regret Score on the Regret Scale, by averaging all 5 individual regret scores, `regret1` to `regret5`
* `maxi_total`, for overall Maximizing score on the Maximizing Scale, by averaging all 6 individual regret scores, `maxi1` to `maxi6`

```{r TEACH ME mutate}
IntroSurvey <- mutate(IntroSurvey,
                      regret_total = (regret1 + regret2 + regret3 + regret4 + regret5) / 5,
                      maxi_total = (maxi1 + maxi2 + maxi3 + maxi4 + maxi5 + maxi6) / 6)
```

You will be using the function `mutate()` that you see above to **add new columns to a dataframe,** or **overwrite existing columns in a dataframe.** Anytime you want to calculate a new column that may be some combination of existing columns, like averaging the values across multiple columns, `mutate()` is the function you want.

You can create as many new columns as you want inside of one `mutate()` command, as long as you separate each row of column-creating code with a comma. To help your code look more readable, press Enter after the comma at the end of each row of column-creating code, to actually get each row of code on its own row.

Now, it's your turn to calculate some new columns of data.

The Maximizing Scale has been shown to divide up into three subscales:

* Alternative Search (`maxi1` & `maxi3`)
* Decision Difficulty (`maxi2` & `maxi5`)
* High Standards (`maxi4` & `maxi6`)

Please use the approach seen above to assign three new variables in the `IntroSurvey` dataframe, each of which represents one subscale: `maxi_as`, `maxi_dd`, and `maxi_hs`. (Hint: you should be averaging the two `maxi` scores for each.)

```{r}
# Code goes here

```

### c. Categorical variables: recoding decision mode and school affiliation

Above, we used `mutate()` to create new **continuous** variables by averaging the values of other continuous variables together. We can also create new **categorical** variables by recoding the values of existing categorical variables into levels that are more convenient for the statistics we want to calculate.

The question about decision mode allowed for 4 options (calculation, rule, role, and affect). To do a t-test, we need the variable **re-coded** as binary, with two levels: calculation vs. not-calculation. To do this, we'll use the `ifelse()` function with `mutate()` to generate a new column in the data again. The code below tells R to create a new variable (`dec_mode_binary`) whose value is `"calc"` _if_ the original variable (`dec_mode`) started with the phrase  "calculation-based", and whose value is `"not-calc"` _otherwise._

```{r TEACH ME ifelse 1}
IntroSurvey <- mutate(IntroSurvey,
                      dec_mode_binary = ifelse(startsWith(dec_mode, "calculation-based"),
                                          "calc",
                                          "not-calc"))
```

There are various strategies you can use to recode the levels of categorical variables. Above, we used a logical test to create a binary variable based on whether the logical test returned true or false. Creating binary variables is very useful for setting up t-tests, because t-tests require you to split your data up into two groups for comparison.

Next, let's create another new binary variable. This time, we will re-code school affiliation into a binary variable Later, we can use this to test for differences in scores by school affiliation (Columbia College/Barnard vs GS/SPS, for example).

To do this, we'll use the `ifelse()` function with `mutate()` to generate a new column in our data, like we did earlier. The code below tells R to create a new variable (`school_binary`) whose value is `"B_CC"` _if_ the original variable (`school`) was _either_ Barnard or CC, and whose value is `"GS_SPS"` _otherwise._

```{r TEACH ME ifelse 2}
IntroSurvey <- mutate(IntroSurvey,
                      school_binary = ifelse(school %in% c("Barnard", "CC"),
                                             "B_CC",
                                             "GS_SPS"))
```

Now it's your turn. Use `mutate()` and `ifelse()` as we demonstrated above to create another binary variable based on handedness. Right now, handedness may have up to 3 levels: "R", "L", or "A" (for ambidextrous). Create a new binary variable called `handed_binary` with two levels: "R" and "notR", where anyone who is not right-handed has the value "notR".

```{r}
# Code goes here

```


## 5. Checking to make sure your manipulation code worked

Use `head()` to check that the following new variables are present in `IntroSurvey`:

* `regret_total`
* `maxi_total`
* `maxi_as`, `maxi_dd`, & `maxi_hs`

```{r}
# Code goes here

```


# Calculating descriptive statistics

## 6.

### a. Calculate means/SDs using summarize()

Now we can start doing some real data analysis! For the purposes of getting practice in a variety of inferential statistics in R, we'll be running more exploratory tests than would normally be considered wise for a real study. We'll talk more about why this is a problem later in the semester, but hopefully in your stats class you talked about the dangers of running too many tests--i.e., alpha-inflation.

Let's start with some descriptive summary statistics on our new variables.

To calculate multiple summary statistics on one dataframe at once, we will use `summarize()`. As an example, first let's calculate both the mean and standard devation of the total regret score across all subjects.

```{r TEACH ME summarize}
# First, create a summary dataframe to hold the relevant info
regret_total_summary <- summarize(IntroSurvey,
                                  mean_regret_total = mean(regret_total, na.rm = TRUE),
                                  sd_regret_total = sd(regret_total, na.rm = TRUE))

# Then print the dataframe to show the summary values inside
regret_total_summary
```

The syntax you use to calculate summary stats with `summarize()` is similar to the syntax you use to create new columns with `mutate()` like we did earlier. You can calculate multiple summary stats in the same `summarize()` command as long as you separate every new stat you want to calculate with a comma.

Use `mean()` and `sd()` inside of `summarize()` to find the mean and standard deviations for:

total maximizing score

```{r}
# Code goes here

```

each of the 3 maxi subscales (You can do this all inside of one `summarize()` call) 

```{r}
# Code goes here

```

### b. Show quick histograms using hist()

Next, we will use `hist()` to visualize the distribution of scores for continuous variables in our data. As a refresher, `hist()` works a little differently than most of the functions we will use in this assignment. In most of the functions we are using, **you already specify to the function that it should look inside `IntroSurvey`, so you do not need to use the `$` to tell R where to find the columns you're referring to.** However, `hist()` isn't that smart, so you will need to use the `$` to tell it to generate a histogram of a specific column inside of a larger dataframe in your environment.

As an example, we will first generate a histogram of the distribution of total regret scores over all students in the data.

```{r TEACH ME hist}
hist(IntroSurvey$regret_total)
```

Now, on your own, use `hist()` like we did above to generate histograms for the columns that you just calculated the mean and standard deviation for in question 6a:

total maximizing score

```{r}
# Code goes here

```

each of the 3 maxi subscales:

Alternative Search

```{r}
# Code goes here

```

Decision Difficulty

```{r}
# Code goes here

```

High Standards

```{r}
# Code goes here

```

### c. Count categorical values using count()

Histograms are a fantastic way to visualize a summary of continuous, numeric variables. However, not all data are numeric--sometimes variables of interest are _categorical_, where each observation is one of a few specified levels.

We can use the function `count()` to see how many observations occur at each level of a categorical variable. For example, let's use `count()` to count how many values are in each level of the column `class`. This will tell us how many participants are in each class year in our `IntroSurvey` data.

```{r TEACH ME count}
count_class <- count(IntroSurvey,
                     class)

count_class
```

`school`

```{r}
# Code goes here

```

`handed`

```{r}
# Code goes here

```


### d.

Explore at least **3** other variables that you think might have a relationship with maximizing and/or regret.

If the variable is _numeric_ or _interval_ (i.e., if its responses are numbers), use `summarize()` with `mean()` and `sd()` to compute the mean and standard deviation, and use `hist()` to produce a histogram.

If the variable is _categorical_, use `count()` to count the values in each level of the variable.

```{r}
# Code goes here

```

```{r}
# Code goes here

```

```{r}
# Code goes here

```

## 7. Calculating summary statistics for different groups

Many times, when investigating summary statistics to learn more about your data, you will want to compare values for different study groups in your participant population, in addition to reporting data across all subjects as we just learned how to do.

Here, we will learn about some functions that will help you break up your summaries by participant groups.

### a. Using filter() to choose subsets of rows of data

First, you can use the `filter()` function to choose a subset of rows out of your data, so you can produce summaries on one group at a time.

```{r TEACH ME filter}
righties <- filter(IntroSurvey,
                   handed == "R")
```

Inside of `filter()`, you use logical statements based on columns of your data to choose which rows to subset. If you use multiple logical statements in the same `filter()` command, separated with commas, you will choose the _intersection_ of all those logical statements, or all the rows where the first statement _and_ the second statement _and_ the third statement etc. are true.

Below, use `filter()` to choose the subset of your data belonging to Columbia College-affiliated right-handed students. You can use the code above to help you, but this time, you will need _two_ logical statements inside of `filter()`.

```{r}
# Code goes here

```

Sometimes, you may want to choose just a subset of your data to operate on, but other times, you may want to calculate all summary statistics for different groups in your data at once, so you can compare them. We will learn how to do this next.

### b. using group_by() and summarize() to generate summary statistics for all groups at once

Remember the `summarize()` function from before? Previously, we used it to calculate summary statistics over all observations in our data. We can also use `summarize()` to calculate statistics separately for different groups in our data. In order to do this, we must tell R what groups are in our data, using a new function, `group_by()`. Then, `summarize()` will automatically calculate summary statistics separately for every group it sees in the data.

Here's an example: Let's calculate the mean and SD of students' total regret scores, like we did in question 6a. This time, however, we will calculate it separately for students of every class year.

```{r TEACH ME group by summarize}
# First, create a summary dataframe to hold the relevant info
regret_total_by_class_summary <- IntroSurvey %>%
  group_by(class) %>%
  summarize(mean_regret_total = mean(regret_total, na.rm = TRUE),
            sd_regret_total = sd(regret_total, na.rm = TRUE))

# Then print the dataframe to show the summary values inside
regret_total_by_class_summary
```

If you run the code above, you'll see that you get columns for mean regret score and SD of regret score, but now instead of one summary value for all subjects, there's a separate value for each level of `class`, corresponding to each unique class year reported in the data.

There is also a new command used in the code above: the pipe operator, `%>%`. The `%>%` operator does one simple, but **key,** thing: takes the object on the left-hand side and feeds it into the first argument of the function on the right-hand side.

This means that you can put multiple functions together, one after the other, and R will understand and execute them in _left to right, like natural English._ In the code above, this means that we are telling R to do these things in this order:

1. Take the `IntroSurvey` data object
2. Use `group_by()` on `IntroSurvey` to tell R to group the rows of `IntroSurvey` by the `class` column
3. Use `summarize()` on the grouped `IntroSurvey` data, calculating a mean and SD of `regret_total`

It's **very important** here that `group_by()` is called _before_ `summarize()`, because otherwise R wouldn't know how to group the data before summarizing it.

We will practice this a couple times.

Below, group `IntroSurvey` by school affiliation (CC, Barnard, GS, etc), and then calculate mean and SD of total regret score for each school group in the data.

```{r}
# Code goes here

```

Below, group `IntroSurvey` by major affiliation, and then calculate mean and SD of total maximizing score for each major in the data.

```{r}
# Code goes here

```

# Calculating inferential statistics

## 7. Correlations

Now that you have a sense for what the data show, let's look at how some of the variables relate to each other. First, some correlations.

### a.

Let's see if age correlates with birthyear (it should!). The function `cor.test()` allows us to put in two variables, see what their correlation is, and return a p-value for that correlation.

The R syntax for a correlation is `cor.test(~ var1 + var2, data = DataFrame)`. Note that because we're defining the dataframe (for today's assignment, `IntroSurvey`) within the test, we don't need to dollar-sign index it in the names of the variables. We can just use the variable name on its own (for example, inside this function, if age were one of our variables, we only need to call `age`, not `IntroSurvey$age`, because `cor.test()` already knows to look inside of `IntroSurvey`.)

`cor.test()` allows you to run a Pearson, Kendall, or Spearman correlation, depending on what you tell it to do using the argument `method`. This time, since we want to do a Pearson correlation, we'll use `method = "pearson"`.

First, we'll save the contents of our correlation test into the variable `cor_age_birthyear` so we can access its contents later. Then, we'll print `cor_age_birthyear` to the console, so we can visually inspect the results of the correlation test.

```{r TEACH ME cor.test}
cor_age_birthyear <- cor.test(~ age + birthyear, method = "pearson", data = IntroSurvey)

cor_age_birthyear
```

Above, you can see the r-value, p-value, and several other pieces of info about the correlation test. These statistics are actually saved as variables _inside of_ the correlation test object. To extract these statistics and report them, we can use the dollar sign `$` to index these statistics, similar to indexing columns in a dataframe.

To index the Pearson's r for this test, we can look for the sub-variable called `estimate`:

```{r}
cor_age_birthyear$estimate
```

And to index the p-value, we can call the sub-variable `p.value`:

```{r}
cor_age_birthyear$p.value
```

Now, we can use these variable names to refer to the Pearson's r and p-value of this correlation test. You don't have to look at the numbers and copy them over!

PS: In RStudio, if you want to know all the sub-variables inside of an object, if you type the name of the object with a `$` after it, an auto-complete menu should pop up and you can use the up and down arrow keys to look through all the possible sub-variables.

### b.

Let's see if maximizing correlates with regret. Use `cor.test()` on those two variables, and report the Pearson's r and p-value.

```{r}
# Code goes here

```

```{r}
# Code goes here

```

```{r}
# Code goes here

```

Typically, maximizing correlates reasonably strongly with regret (r ~ 0.4). Does this appear to be the case in our dataset? 

### c.

Let's see if maximizing correlates with various measures of course-selection behavior. Calculate the correlation and report the Pearson's r between `maxi_total` and each of the following variables:

`courses_enrolled`

```{r}
# Code goes here

```

`courses_shopped`

```{r}
# Code goes here

```

`points_enrolled`

```{r}
# Code goes here

```

### d.

Is the regret score (`regret_total`), as calculated by the Regret Scale, correlated with either of our students' self-reports of regret:

`process_regret`?

```{r}
# Code goes here

```

`outcome_regret`?

```{r}
# Code goes here

```

What about `regret_general`?

```{r}
# Code goes here

```

### e.

Is the score on the Maximizing Scale (`maxi_total`) related to the self-report of tendency to maximize (`maxi_general`)?

```{r}
# Code goes here

```

## 8. T-tests

We use t-tests to determine if two samples likely come from different populations. Of course, means will always differ somewhat, even if two samples are drawn from the same population. When the t-value is high enough, we conclude that it's unlikely that the two samples actually represent the same population.

The R syntax for a Student's t-test is `t.test(dv ~ iv, data = DataFrame)`. Note that because we're defining the dataframe (for today's assignment, `IntroSurvey`) within the test, we don't need to dollar-sign index it in the names of the DV and IV variables. We can just use the variable name on its own (for example, inside this function, if age were our DV, we only need to call `age`, not `IntroSurvey$age`, because `t.test()` already knows to look inside of `IntroSurvey`.)

### a. 

Let's start by seeing if our subjects show a difference in age based on handedness. (They shouldn't!)

Note: t-tests can only be run on **two groups.** Earlier in question 4c, we created a new binary handedness variable called `handed_binary` that we can now use to separate two groups for our t-test.

```{r TEACH ME t.test}
t_age_handed <- t.test(age ~ handed_binary, data = IntroSurvey)

t_age_handed
```

Similarly to `cor.test` objects, if you save the output of `t.test()` into a variable, you can dollar-sign index into its sub-variables to access the estimated means, t-value, p-value, etc. from the test.

```{r}
t_age_handed$estimate
```

```{r}
t_age_handed$statistic
```

```{r}
t_age_handed$p.value
```

### b.

Next, you'll create and inspect your own t-test objects. This time, let's test for differences in scores by school affiliation (Columbia College/Barnard vs GS/SPS, for example). We will use the `school_binary` variable that we created earlier in question 4c. If you can't remember how this variable was created, refer back to the code in that question.

Does regret score differ by school affiliation?

```{r}
# Code goes here

```

### c.

Does tendency to maximize differ by school affiliation?

```{r}
# Code goes here

```

### d.

It might be reasonable to expect that people who made their course decisions using a calculation-based mode are more likely to be maximizers than those who used an affect- or rule-based mode. So we should see if there's any difference in maximizing between those who used calculation-based modes and those who didn't.

Remember, the original decision mode variable, `dec_mode` has 4 options (calculation, rule, role, and affect). To do a t-test, we need to use the binary-recoded version of this variable, `dec_mode_binary`. We created this variable earlier in question 4c, so if you can't remember how this variable was created, refer back to the code in that question.

Now, please run a t-test just like above, with `dec_mode_binary` as the IV and total maximizing score as the DV.

```{r}
# Code goes here

```

# Graphing data

## 9.

Time to graph some results! `ggplot2` is a package that helps you make prettier figures in R, using more straightforward syntax. We'll use `ggplot2` to make a scatterplot and a bar graph, but first let's get oriented with how it works.

At the beginning of this lab, you installed the package `ggplot2`. You only have to do that once ever (unless you uninstall it or update the package).

We also loaded the `ggplot2` library, which allows us to quickly access all of its functions, with the `library(ggplot2)` command. You need to do that once every time you open a new R session.

`ggplot2` allows you to format your figures in many cool ways. When working on one complete project, whether it be one homework assignment or one set of research analyses, it's easiest to just define a "theme" one time, and then apply it to every figure in that set of analyses.

We'll create a theme called `bwtheme` (for black & white), which is nice and simple. We'll use some `ggplot2` functions to define this theme and save it into a variable. This way, you can create the theme variable once and then use it over and over on multiple graphs. Run the code below to save our theme into a variable:

```{r RUN ME bwtheme}
bwtheme <- theme_bw() + 
  theme(strip.background = element_rect(fill = 'white')) +
  theme(plot.title = element_text(size = rel(1))) + 
  theme(axis.title = element_text(size = rel(1)))
```

When you plot data with `ggplot2`, you need to tell it 3 things:

1. what type of plot to make (e.g., scatter, bar chart)
2. what data to plot (e.g., what variables are your x and y values?)
3. what extra layers do you want to add (e.g., a regression line)

After you tell `ggplot2` one thing about what you want your plot to look like, if you put a `+` after one plotting call it knows that you have more information to give it about the same plot. 

It's best practice to add a new line after each separate layer of your plotting code, so that each layer's code is easily readable on its own. You can add as many layers to your plotting command as you'd like as long as you end each line with a `+` (except the last line).

For example, to plot a scatterplot of `age` and `birthyear`, you would use:

```{r TEACH ME ggplot 1}
ggplot(IntroSurvey, aes(x = birthyear, y = age)) +
  geom_point(shape = 1) +
  bwtheme
```

The `ggplot()` command defines the dataframe (`IntroSurvey`) and the "aesthetics" (the x and y variables you want to use). The `geom_point()` command tells `ggplot2` you want to graph points (aka a scatter plot). `shape = 1` tells `ggplot2` to use open circles for each point. `ggplot2` supports several different point shapes in scatter plots, each labeled by a different number. You can experiment with different shapes by changing the number, if you'd like.

One useful thing to add to a scatterplot is a linear regression line. (A correlation between x and y is the same as a linear regression with only one predictor variable.) We'll do this with `geom_smooth()`.

```{r TEACH ME ggplot 2}
ggplot(IntroSurvey, aes(x = birthyear, y = age)) +
  geom_point(shape = 1) +
  geom_smooth(method = lm) +
  bwtheme
```

By default, `geom_smooth()` will graph the 95% confidence interval (CI) for your regression line. If you want to omit that line, set the `se` argument (stands for "standard error") of `geom_smooth()` to be `FALSE` to turn the estimated standard error off, like this: `geom_smooth(method = lm, se = FALSE)`

Earlier, you found the correlation between regret and maximizing. Let's graph that now. This time, we'll add a title by adding an additional layer in our `ggplot` call, and we'll also edit the x and y axis labels so that they're a little more informative than our shorthand variable names.

```{r TEACH ME ggplot 3}
ggplot(IntroSurvey, aes(x = maxi_total, y = regret_total)) +
  geom_point(shape = 1) +
  geom_smooth(method = lm) +
  # labs() lets you modify various labels in a ggplot
  labs(title = "Regret as a Function of Maximizing Tendency",
       x = "tendency to maximize",
       y = "tendency toward regret") +
  bwtheme
```

## 10.

Create one more figure that shows the relationship between two _continuous_ variables (or any variables that _aren't categorical_). Make sure your figure has a title, and change the labels on each axis so that someone not familiar with our variable names would understand what the figure represents. 
You can copy and paste code from the previous sections, above, but remember to change the variable names as needed.

```{r}
# Code goes here

```

## 11.

Now let's make a box plot, which is a clean way to illustrate the centers and spreads of multiple categories (e.g., the two groups you're comparing with a t-test) . We'll graph this in the same way as we made the scatter plot, but this time instead of using `geom_point()` to create a scatter plot we'll use `geom_boxplot()` to generate a box plot.

```{r TEACH ME ggplot 4}
ggplot(IntroSurvey, aes(x = handed, y = age)) +
  geom_boxplot() +
  bwtheme  
```

`geom_boxplot()` shows you the median (middle line of the box), the 25th and 75th percentiles (the bottom and top edges of the box), and +- 1.5 inter-quartile ranges (IQRs) away from the median (the whiskers). Any points farther than 1.5 IQRs from the median are shown as individual points.

If you want to add the points over the boxplots (a good habit, so that your reader can see where the individual values fall, in addition to the summary statistics), you can easily do this by adding another layer on top of `geom_boxplot()` using something like `geom_point(size = 3, alpha = .5)`. The alpha value is opacity (transparency), where larger fractions (closer to 1) are more opaque and lower fractions (closer to 0) are more transparent.

```{r TEACH ME ggplot 5}
ggplot(IntroSurvey, aes(x = handed, y = age)) +
  geom_boxplot() +
  geom_point(size = 3, alpha = .3) +
  bwtheme
```

If you want to change the order of the x-axis labels, or change their text, you can change these with various arguments within `scale_x_discrete()`. There are several functions you can use to modify the behavior of x-axes and y-axes. In this case, because the x variable is categorical, `scale_x_discrete()` is the appropriate function to use.

```{r TEACH ME ggplot 6}
ggplot(IntroSurvey, aes(x=handed, y=age)) +
  geom_boxplot() +
  geom_point(size = 3, alpha = .3) +
  bwtheme   +
  scale_x_discrete(limits = c("L", "R", "A"), # limits re-orders the three bars
                   # labels changes text.
                   # Make sure these are specified in the correct order!
                   labels = c("Left", "Right", "Ambi"))
```

Finally, if making the points transparent doesn't solve the problem of telling overlapping points apart, you can "jitter" the location of each point horizontally by using `geom_jitter()` in place of `geom_point()`. This adds a little bit of random noise to each point's location, which makes it so that points which were on top of each other are now slightly offset.

Below, the `geom_point()` line has been commented out so it won't run. R will skip over it and run the `geom_jitter()` line below it and keep going as usual. If you uncomment `geom_point()` by deleting the #, and instead comment out the `geom_jitter()` line by adding a # in front it, you'll see your partially transparent points again. 

Since both of these commands alter the way points are plotted by `ggplot2`, you should only use _one at a time._

```{r TEACH ME ggplot 7}
ggplot(IntroSurvey, aes(x=handed, y=age)) +
  geom_boxplot() +
  # geom_point(size = 3, alpha = .3) +
  geom_jitter(position=position_jitter(width=.1, height=0)) +
  bwtheme   +
  scale_x_discrete(limits=c("L","R","A"),
                   labels=c("Left", "Right", "Ambi"))
```

Now, please create one new box plot that shows any of our continuous DVs as a function of one of our categorical variables. Again, make sure your figure has a title, and change the labels on each axis so that someone not familiar with our variable names would understand what the figure represents. 

```{r}
# Code goes here

```

# Submitting this assignment

When saving an R Markdown, you can either save it as a text-based file so you can keep editing it and running the code inside later, or you can export it as a final document that anyone can read without opening RStudio. Exporting an R Markdown is called "knitting." To knit your file, click the "Knit" button at the top of your Editor pane, and click "Knit to HTML." Once the HTML document finishes exporting, it should save into the same directory as your original R Markdown file. Rename this HTML document with a **new filename** that _includes your own name,_ e.g. R_Project_2_Monica_Thieu.html or R_Project_2_Paul_Bloom.html .

To get credit for this assignment, upload your completed "knitted" HTML to the Assignments section of Canvas for UN1490.
